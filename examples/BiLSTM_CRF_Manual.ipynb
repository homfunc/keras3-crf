{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiLSTM-CRF (manual build)\n",
    "Build the BiLSTM-CRF without train_utils, to show where you can plug custom losses/metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ.setdefault('KERAS_BACKEND', os.getenv('KERAS_BACKEND', 'tensorflow'))\n",
    "import sys, pathlib\n",
    "root = pathlib.Path(__file__).resolve().parents[2]\n",
    "sys.path.insert(0, str(root))\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import layers, ops as K\n",
    "from keras_crf.layers import CRF\n",
    "from keras_crf.crf_ops import crf_log_likelihood, crf_marginals\n",
    "from examples.utils.data import make_varlen_dataset\n",
    "from examples.utils.metrics import MaskedTokenAccuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, _ = make_varlen_dataset(1000, 40, 200, 6, seed=1)\n",
    "X_val, Y_val, _ = make_varlen_dataset(200, 40, 200, 6, seed=2)\n",
    "vocab_size = 200\n",
    "num_tags = 6\n",
    "tokens = keras.Input(shape=(None,), dtype='int32', name='tokens')\n",
    "x = layers.Embedding(vocab_size + 1, 64, mask_zero=True)(tokens)\n",
    "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
    "crf = CRF(num_tags)\n",
    "decoded, potentials, lens, trans = crf(x)\n",
    "labels = keras.Input(shape=(None,), dtype='int32', name='labels')\n",
    "\n",
    "class NLL(keras.layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        pot, y_true, ln, tr = inputs\n",
    "        return -crf_log_likelihood(pot, y_true, ln, tr)\n",
    "\n",
    "class Dice(keras.layers.Layer):\n",
    "    def __init__(self, n, s=1.0, **kw):\n",
    "        super().__init__(**kw); self.n=n; self.s=s\n",
    "    def call(self, inputs):\n",
    "        pot, y_true, ln, tr = inputs\n",
    "        T = K.shape(pot)[1]\n",
    "        probs = crf_marginals(pot, ln, tr)\n",
    "        y_oh = K.one_hot(K.cast(y_true, 'int32'), self.n)\n",
    "        y_oh = K.cast(y_oh, probs.dtype)\n",
    "        mask = K.expand_dims(K.cast(K.arange(T)[None, :] < K.cast(ln[:, None], 'int32'), probs.dtype), -1)\n",
    "        inter = K.sum(y_oh*probs*mask, axis=(1,2))\n",
    "        sums = K.sum(y_oh*mask, axis=(1,2)) + K.sum(probs*mask, axis=(1,2))\n",
    "        dice = (2*inter + self.s)/(sums + self.s)\n",
    "        return 1.0 - dice\n",
    "\n",
    "nll = NLL()([potentials, labels, lens, trans])\n",
    "dice = Dice(num_tags)([potentials, labels, lens, trans])\n",
    "\n",
    "combo = keras.layers.Lambda(lambda zs: 0.2*zs[0] + 0.8*zs[1])([nll, dice])\n",
    "\n",
    "class _Id(keras.layers.Layer):\n",
    "    def __init__(self, **kw): super().__init__(**kw); self.supports_masking=True\n",
    "    def call(self, x): return x\n",
    "\n",
    "decoded_out = _Id(name='decoded_output')(decoded)\n",
    "loss_out = keras.layers.Lambda(lambda z: z, name='crf_log_likelihood_output')(combo)\n",
    "model = keras.Model({'tokens': tokens, 'labels': labels}, {'decoded_output': decoded_out, 'crf_log_likelihood_output': loss_out})\n",
    "\n",
    "def zero_loss(y_true, y_pred):\n",
    "    return K.mean(K.zeros_like(y_pred[..., :1]))\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(1e-3),\n",
    "              loss={'decoded_output': zero_loss, 'crf_log_likelihood_output': lambda yt, yp: K.mean(yp)},\n",
    "              metrics={'decoded_output': [MaskedTokenAccuracy()]})\n",
    "\n",
    "y_train = {'decoded_output': Y_train, 'crf_log_likelihood_output': np.zeros((X_train.shape[0],), np.float32)}\n",
    "sw_train = {'decoded_output': (X_train!=0).astype(np.float32), 'crf_log_likelihood_output': np.ones((X_train.shape[0],), np.float32)}\n",
    "y_val = {'decoded_output': Y_val, 'crf_log_likelihood_output': np.zeros((X_val.shape[0],), np.float32)}\n",
    "sw_val = {'decoded_output': (X_val!=0).astype(np.float32), 'crf_log_likelihood_output': np.ones((X_val.shape[0],), np.float32)}\n",
    "\n",
    "model.fit({'tokens': X_train, 'labels': Y_train}, y_train, sample_weight=sw_train, validation_data=({'tokens': X_val, 'labels': Y_val}, y_val, sw_val), epochs=2, batch_size=64, verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd5fd21",
   "metadata": {},
   "source": [
    "## CleanCoNLL and MultiCoNER via train_lib (importable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae957f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples import train_lib as tl\n",
    "# CleanCoNLL (after preparing splits)\n",
    "# X_tr, Y_tr, X_va, Y_va, X_te, Y_te, V, C, id2tag = tl.load_conll('examples/data/cleanconll/train.txt', 'examples/data/cleanconll/valid.txt', 'examples/data/cleanconll/test.txt')\n",
    "# model2, pred2 = tl.build_bilstm_crf_models(V, C, loss='dice+nll', joint_nll_weight=0.2)\n",
    "# tl.train_and_evaluate(model2, pred2, X_tr, Y_tr, X_va, Y_va, X_te, Y_te, epochs=2, batch_size=64, id2tag=id2tag)\n",
    "# MultiCoNER EN-English\n",
    "# X_tr, Y_tr, X_va, Y_va, X_te, Y_te, V, C, id2tag = tl.load_multiconer_en('examples/data/multiconer/EN-English')\n",
    "# model3, pred3 = tl.build_bilstm_crf_models(V, C, loss='dice+nll', joint_nll_weight=0.2)\n",
    "# tl.train_and_evaluate(model3, pred3, X_tr, Y_tr, X_va, Y_va, X_te, Y_te, epochs=2, batch_size=64, id2tag=id2tag)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
